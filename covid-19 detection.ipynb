{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covid Xray Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'covid-chestxray-dataset-master/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root+'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'images/'\n",
    "COVID_PATH = 'combined_dataset/covid'\n",
    "NORMAL_PATH = 'combined_dataset/normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for (i,row) in df.iterrows():\n",
    "    if row['finding'] == 'COVID-19' and row['view'] == 'PA':\n",
    "        f = row['filename']\n",
    "        src_path = os.path.join(root,IMAGE_PATH,f)\n",
    "        dest_path = os.path.join(COVID_PATH,f)\n",
    "        shutil.copy2(src_path,dest_path)\n",
    "        cnt +=1\n",
    "        print(cnt,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal XRay Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root2 = \"chest_xray/train/NORMAL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = os.listdir(root3)[:142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for f in normal_data:\n",
    "    src_path = os.path.join(root3,f)\n",
    "    dest_path = os.path.join(NORMAL_PATH,f)\n",
    "    shutil.copy2(src_path,dest_path)\n",
    "    cnt +=1\n",
    "    print(cnt,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(NORMAL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_x_dir = os.listdir(NORMAL_PATH)\n",
    "covid_x_dir = os.listdir(COVID_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal_train, x_normal_val = train_test_split(normal_x_dir, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_covid_train, x_covid_val = train_test_split(covid_x_dir, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "PATH = 'combined_dataset/train'\n",
    "for fn,fc in zip(x_normal_train,x_covid_train):\n",
    "    src_path_norm = os.path.join(NORMAL_PATH,fn)\n",
    "    src_path_cov = os.path.join(COVID_PATH,fc)\n",
    "    dest_path_norm = os.path.join(PATH,'normal',fn)\n",
    "    dest_path_cov = os.path.join(PATH,'covid',fc)\n",
    "    shutil.move(src_path_norm,dest_path_norm)\n",
    "    shutil.move(src_path_cov,dest_path_cov)\n",
    "    cnt +=1\n",
    "    print(cnt,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "PATH = 'combined_dataset/val'\n",
    "for fn,fc in zip(x_normal_val,x_covid_val):\n",
    "    src_path_norm = os.path.join(NORMAL_PATH,fn)\n",
    "    src_path_cov = os.path.join(COVID_PATH,fc)\n",
    "    dest_path_norm = os.path.join(PATH,'normal',fn)\n",
    "    dest_path_cov = os.path.join(PATH,'covid',fc)\n",
    "    shutil.move(src_path_norm,dest_path_norm)\n",
    "    shutil.move(src_path_cov,dest_path_cov)\n",
    "    cnt +=1\n",
    "    print(cnt,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import * \n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dg = image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dg = image.ImageDataGenerator(\n",
    "    rescale=1./255,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 226 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_dg.flow_from_directory(\n",
    "    'combined_dataset/train',\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid': 0, 'normal': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = val_dg.flow_from_directory(\n",
    "    'combined_dataset/val',\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid': 0, 'normal': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 220, 220, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 108, 108, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                5537856   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,668,097\n",
      "Trainable params: 5,668,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "8/8 [==============================] - 123s 15s/step - loss: 1.1676 - acc: 0.5193 - val_loss: 0.6790 - val_acc: 0.5862\n",
      "Epoch 2/16\n",
      "8/8 [==============================] - 107s 13s/step - loss: 0.6321 - acc: 0.6586 - val_loss: 0.6076 - val_acc: 0.6897\n",
      "Epoch 3/16\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.5261 - acc: 0.7820 - val_loss: 0.3958 - val_acc: 0.9483\n",
      "Epoch 4/16\n",
      "8/8 [==============================] - 110s 14s/step - loss: 0.3142 - acc: 0.8573 - val_loss: 0.2707 - val_acc: 0.9310\n",
      "Epoch 5/16\n",
      "8/8 [==============================] - 111s 14s/step - loss: 0.2527 - acc: 0.8567 - val_loss: 0.2977 - val_acc: 0.9828\n",
      "Epoch 6/16\n",
      "8/8 [==============================] - 111s 14s/step - loss: 0.3571 - acc: 0.8850 - val_loss: 0.3019 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "8/8 [==============================] - 108s 13s/step - loss: 0.1907 - acc: 0.9287 - val_loss: 0.1291 - val_acc: 0.9828\n",
      "Epoch 8/16\n",
      "8/8 [==============================] - 109s 14s/step - loss: 0.1265 - acc: 0.9564 - val_loss: 0.0767 - val_acc: 0.9655\n",
      "Epoch 9/16\n",
      "8/8 [==============================] - 110s 14s/step - loss: 0.1388 - acc: 0.9524 - val_loss: 0.0373 - val_acc: 0.9828\n",
      "Epoch 10/16\n",
      "8/8 [==============================] - 109s 14s/step - loss: 0.0622 - acc: 0.9683 - val_loss: 0.0769 - val_acc: 0.9655\n",
      "Epoch 11/16\n",
      "8/8 [==============================] - 106s 13s/step - loss: 0.1046 - acc: 0.9802 - val_loss: 0.0546 - val_acc: 0.9828\n",
      "Epoch 12/16\n",
      "8/8 [==============================] - 94s 12s/step - loss: 0.1851 - acc: 0.9445 - val_loss: 0.1487 - val_acc: 0.9138\n",
      "Epoch 13/16\n",
      "8/8 [==============================] - 75s 9s/step - loss: 0.3001 - acc: 0.9445 - val_loss: 0.2577 - val_acc: 0.9483\n",
      "Epoch 14/16\n",
      "8/8 [==============================] - 71s 9s/step - loss: 0.1688 - acc: 0.9564 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "8/8 [==============================] - 70s 9s/step - loss: 0.1029 - acc: 0.9723 - val_loss: 0.0362 - val_acc: 0.9828\n",
      "Epoch 16/16\n",
      "8/8 [==============================] - 70s 9s/step - loss: 0.0859 - acc: 0.9723 - val_loss: 0.0567 - val_acc: 0.9828\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=8,\n",
    "    epochs = 16,\n",
    "    validation_data = val_gen,\n",
    "    validation_steps = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0690689796037906, 0.9867256637168141]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(train_gen,steps=len(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05668369295268223, 0.9827586083576597]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(val_gen,steps=len(val_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"combined_dataset/val/\"\n",
    "for f in os.listdir(PATH+'normal/'):\n",
    "    img = image.load_img(PATH+'normal/'+f,target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    pred = model.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    y_true.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"combined_dataset/val/\"\n",
    "for f in os.listdir(PATH+'covid/'):\n",
    "    img = image.load_img(PATH+'covid/'+f,target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    pred = model.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    y_true.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21487d6ea20>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD+FJREFUeJzt3X+Q1PV9x/HXaw+dJoKMPwICmohKqjA2WtH80Bl1NMZIFaxRyxglkenZplZF05GYtiZNm9pO1WYynWQuI1UbI9WoI1qbRB0MY9qqaIhCwBoZKsddoAaLqHGE3Xf/2DXuwHG7d7ef3e9+eD5mvsPud28/+x7ueN2bz/fz/X4dEQIApFPqdAEAkDuCFgASI2gBIDGCFgASI2gBIDGCFgASI2gBIDGCFgASI2gBILFxqT8gls/i1DPs5oIzv9TpElBA95c/67GOse2dI5rOnIn7rh/z5zWDjhYAEkve0QJAW1V6Ol3BbghaAFlxuXj/USdoAWTFlbZMu44IQQsgK650uoLdEbQA8kLQAkBaLuCCUoIWQFaYOgCAxFwuXktL0ALICx0tAKTlCh0tAKRFRwsAabHqAAAS885OV7A7ghZAXqJ4LS1BCyArrKMFgNQIWgBIi4NhAJAaHS0ApOUy16MFgLToaAEgMYIWABLjYBgApMU9wwAgNQ6GAUBiBZyjLd4N0AFgLGIE2zBsH2Z7ue21ttfYvrq2/yu2N9leVdvOaVQSHS2AvLRujnanpOsi4jnbEyQ9a/vR2mu3RsQ/NDsQQQsgL9GaoI2IQUmDtcfbba+VNG00YzF1ACArroxgs3ttr6zbeocc0z5c0vGSnqrtutL287aX2D6gUU0ELYC8lN30FhF9ETG7buvbdTjb4yXdJ+maiHhd0rckHSnpOFU73psblcTUAYC8tHAdre19VA3ZuyLifkmKiM11r39H0sONxqGjBZCXcPPbMGxb0m2S1kbELXX7p9R92fmSVjcqiY4WQF5at472ZEmXSnrB9qravhskzbd9nKoLxDZIuqLRQAQtgLy0btXBk5KGGuyRkY5F0ALISoxgjrZdJ+sStADywrUOACCxFk0dtBJBCyAvXCYRABKjowWAxOhoASCt4GAYACTG1AEAJMbUAQAkRkcLAInR0QJAWtHgXmCdQNACyEu5eFd/JWgBZCWYo917DG4NXX97Ra++HipZuuiUki47o6RvPlTWvU+GDpxQ/bpFc0s69dji/QZGe5RK1t8//WltHXhLXz/viU6XkwfmaPcePT3S9Z8padYHrTfeDl3w9bI+cUz1B2DBGSUtPItwhTTnqqPVv26b3r//Pp0uJR/d2NHaPlrSXFVvsxuSBiQti4i1iWvrapMmWpMmVh+P/y3ryEOszf9XwFl6dMxB096vE86Zqu//7Wqdt+iYTpeTjSJOHQzbVtm+XtJSVa+P+7SkZ2qP77a9OH15eeh/NbR2Y+gj06s/AHc9UdF5X9upG+4sa9ubhO/e6vJbT9Cdi3+qaN2tVyBVb2XT7NYmjTrahZJmRcSO+p22b5G0RtJNqQrLxZtvh67qK+tLF5U0/n3W/FNL+sKc6m+rbyyr6O/uq+jrl/V0uky02Qlzpmnblre1/rmtmnXq5E6Xk5Uo4KqDRhVVJE0dYv8UDfP7wHav7ZW2V/Y9/NpY6utqO8qhq/oqOvekks46vvpXffD+Vk/JKpWsC08p6YUNdLR7o6M/8QGdeO6h+vbL83Tt907RsacfoqvvPLnTZeWhRXfBbaVGHe01kh63/ZKkjbV9H5R0lKQr9/SmiOiT1CdJsXzWXpkkEaE/v7OiIw+RPn/me7/PtmwLTZpY/QY/tio0Y2rx5pOQ3l1fXqW7vly9seqsUydr7nXH6BuX/aTDVeWhiHO0wwZtRPzA9oclnaTqwTBL6pf0TESU21Bf13ruZenBp0IfnibN++udkqpLuf5tZXW+1pamHWR99ZLi/TcH6GrduLwrIiqS/qsNtWTlhKOsdd/e/a/31GM7UAwKbc2PN2vNjzd3uox8dFtHCwDdhgt/A0BiXTdHCwBdh6AFgLSiGw+GAUBXKWBHy9oiAFmJcNPbcGwfZnu57bW219i+urb/QNuP2n6p9ucBjWoiaAFkJcpuemtgp6TrIuIYSR+T9Ce2Z0paLOnxiJgh6fHa82ERtACy0qqONiIGI+K52uPtktaqeuLWXEl31L7sDknzGtXEHC2AvCQ4GGb7cEnHS3pK0uSIGJSqYWx7UqP309ECyMpIOtr6C2DVtt5dx7M9XtJ9kq6JiNdHUxMdLYC8jGDVQf0FsIZiex9VQ/auiLi/tnuz7Sm1bnaKpC2NPoeOFkBWWrjqwJJuk7Q2Im6pe2mZpAW1xwskPdioJjpaAFlp4bUOTpZ0qaQXbK+q7btB1Rse3GN7oaRXJF3YaCCCFkBWWnWtg4h4UtVLww7ljJGMRdACyEsBzwwjaAFkhWsdAEBiXCYRABKLSvEWUxG0ALISe7w/d+cQtADywtQBAKTFHC0AJEbQAkBqBC0ApFUps+oAANKKThewO4IWQFaYowWAxAhaAEiMax0AQGKcggsAiTF1AACJBasOACAtOloASI2DYQCQFh0tACRWYdUBAKRFRwsAqRG0AJAWt7IBgMSYOgCAxAhaAEiMVQcAkBodLQCkVcSpg+L12AAwBhFuemvE9hLbW2yvrtv3FdubbK+qbec0GoegBZCVqDS/NeF2SWcPsf/WiDiutj3SaBCmDgBkpZUHwyJihe3DxzoOHS2ArIxk6sB2r+2VdVtvkx9zpe3na1MLBzT6YoIWQFZGErQR0RcRs+u2viY+4luSjpR0nKRBSTc3egNTBwCyknrVQURsfvex7e9IerjRewhaAFlJHbS2p0TEYO3p+ZJWD/f1UhuCduI5l6b+CHShjb/+y06XgEL67NiHaOEdFmzfLek0SQfb7pd0o6TTbB8nKSRtkHRFo3HoaAFkpcWrDuYPsfu2kY5D0ALICnfBBYDEingKLkELICsELQAkRtACQGIELQAkVikX74RXghZAVuhoASAxghYAEiNoASAxghYAEuMuuACQWLTwojKtQtACyApTBwCQGBeVAYDEKnS0AJAWUwcAkBirDgAgMTpaAEiM5V0AkBgdLQAkRtACQGIELQAkVmbVAQCkRUcLAIlFpdMV7I6gBZAVOloASIxrHQBAYkU8Bbd4FQHAGES46a0R20tsb7G9um7fgbYftf1S7c8DGo1D0ALISiXc9NaE2yWdvcu+xZIej4gZkh6vPR8WQQsgKxHNb43HihWStu6ye66kO2qP75A0r9E4zNECyEobLiozOSIGJSkiBm1PavQGOloAWRnJHK3tXtsr67beFDXR0QLISnkEHW1E9EnqG+FHbLY9pdbNTpG0pdEb6GgBZKWVqw72YJmkBbXHCyQ92OgNdLQAstLKExZs3y3pNEkH2+6XdKOkmyTdY3uhpFckXdhoHIIWQFZaebvxiJi/h5fOGMk4BC2ArHCtAwBIrFwmaAEgKTpaAEiMq3cBQGKtPBjWKgQtgKzQ0QJAYnS0AJDYSE7BbReCFkBW6GgBIDHmaAEgsSJ2tFy9q03O/OR0PfuzP9Sq1Vdo0Rc/1uly0AGbfyn98eU9uui8cbp43jgt/W71n99/vyhdfkmP5p8/Ttde2aM33uhwoV2ulXdYaBU62jYolayb//EszZ2zVJs2bdcTT35Ojzz8kl5c96tOl4Y26umRrv5iWUfPlN58U7rs4nE66eMV/c2NPbr6uop+98TQsges7/5zSX/0p5VOl9u1ijh1QEfbBrNPnKL1L7+mDRu2aceOiu679+ea83szOl0W2uzgD0hHz6w+3m8/afr00P9utl7ZYB0/u9peffTjoeWP8c9yLMrR/NYuo/6O2v58KwvJ2ZSpE9Tfv/03zwc2bdfUaRM6WBE6bWCT9OI6a9bvhI44KrRiebULe+yHJW3+ZYeL63IhN721y1h+dX51Ty/U34fnnZ1Pj+Ej8uAhvp9FnLBHe7z1lrR40Thde31Z48dLf/FXZX1/aUmXXTROb70ljdun0xV2t0o0v7XLsHO0tp/f00uSJu/pffX34dn/fTft9ZEysGm7Dj30vQ526rQJGhzYPsw7kKudO6TrF/XoU3MqOv3M6j+Nw4+QvtlXliT9zwbpJyuKN8fYTYoYOI0Ohk2W9ClJr+2y35L+I0lFGXp25aCOOOpAfehDEzUwsF0XXDhTCz+3rNNloc0ipK/d2KPpR4QuWfDewa6tv5IOPEiqVKQlfT36/Ys4EDYW7exUm9UoaB+WND4iVu36gu0nklSUoXI59GeLfqQHHrpYPT3Wv9zxvNatfbXTZaHNfvZT698fKumoGaFLPlOdtfvCVWVtfMW6d2n1+elnVHTuvAImRRdp50GuZjkSTxYydYChbNw20js8Y28wcd/1Y543WVz616Yz56bKxW2Zp2EdLYCsFHHihaAFkJUi/heaoAWQFTpaAEisiGvUCVoAWSl3uoAhELQAssLUAQAkRtACQGIFnKIlaAHkhY4WABKLFva0tjdI2q7qMbadETF7NOMQtACykmDVwekRMaaLkxC0ALJSxKkD7pkBICvhaHqrv0lBbevddThJP7L97BCvNY2OFkBWRtLR1t+kYA9OjogB25MkPWp7XUSsGGlNdLQAslIZwdZIRAzU/twi6QFJJ42mJoIWQFbKiqa34djez/aEdx9LOkvS6tHUxNQBgKy0cHnXZEkPuHp31XGSvhcRPxjNQAQtgKy0atVBRKyX9JFWjEXQAshKFPAmwgQtgKxUCni1A4IWQFaKeMICQQsgK41WE3QCQQsgK0wdAEBiHAwDgMToaAEgsVZej7ZVCFoAWWHVAQAkxqoDAEisYoIWAJLiYBgAJFa8mCVoAWSGjhYAEttJ0AJAWqyjBYDEmDoAgMRY3gUAiXFmGAAkxtQBACRWLmBPS9ACyAodLQAkRtACQGIELQAkVuFWNgCQFh0tACS2g1UHAJBWETvaUqcLAIBWqiia3hqxfbbtF23/wvbi0dZERwsgK2W3ZurAdo+kf5L0SUn9kp6xvSwifj7SsQhaAFlp4c0ZT5L0i4hYL0m2l0qaK4mgBbB3e6dFHa2kaZI21j3vl/TR0QyUPGhf//XiAq5q6wzbvRHR1+k6imHU013Z4eeitUaSObZ7JfXW7eqr+14MNc6o2mUOhrVXb+MvwV6In4sOiYi+iJhdt9X/wuuXdFjd80MlDYzmcwhaABjaM5Jm2J5ue19JfyBp2WgGYo4WAIYQETttXynph5J6JC2JiDWjGYugbS/m4TAUfi4KKiIekfTIWMdxRPHOogCAnDBHCwCJEbRt0qpT+ZAP20tsb7G9utO1IC2Ctg3qTuX7tKSZkubbntnZqlAAt0s6u9NFID2Ctj1+cypfRLwj6d1T+bAXi4gVkrZ2ug6kR9C2x1Cn8k3rUC0A2oygbY+WncoHoPsQtO3RslP5AHQfgrY9WnYqH4DuQ9C2QUTslPTuqXxrJd0z2lP5kA/bd0v6T0m/bbvf9sJO14Q0ODMMABKjowWAxAhaAEiMoAWAxAhaAEiMoAWAxAhaAEiMoAWAxAhaAEjs/wEJaobYDT29LQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(cn,cmap=\"plasma\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
